{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "# Pytorch import:\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from dataset import *\n",
    "from models import *\n",
    "from path_finding import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fragment(img, n, channel_first=False):\n",
    "    \"\"\" Fragment image into smaller pieces.\n",
    "        Height & width of the images is divided\n",
    "        by a specific number.\n",
    "\n",
    "        Args:\n",
    "            img (2d-array like): Input image for fragmentation.\n",
    "            n (int): The number the height & width be divided into.\n",
    "            channel_first (bool): If True, then color channel is set\n",
    "                    as first channel (suitable for torch tensor).\n",
    "\n",
    "        Return:\n",
    "            fragments (list of 2d-array like): List of fragmented frame.\n",
    "    \"\"\"\n",
    "    h, w, c = img.shape\n",
    "    step_h = h // n\n",
    "    step_w = w // n\n",
    "    fragments = []\n",
    "    for i in range(0, h-step_h+1, step_h):\n",
    "        for j in range(0, w-step_w+1, step_w):\n",
    "            if channel_first:\n",
    "                fragments.append(img[i:i+step_h, j:j+step_w].permute(2, 0, 1))\n",
    "            else:\n",
    "                fragments.append(img[i:i+step_h, j:j+step_w])\n",
    "    return fragments\n",
    "\n",
    "def glue_fragments(img, n):\n",
    "    \"\"\" Combine fragmented framed into a single frame.\n",
    "\n",
    "        Args:\n",
    "            img (2d-array like): Input image for combining.\n",
    "            n (int): The number of fragments per side.\n",
    "\n",
    "        Return:\n",
    "            frame (2d-array like): Glued frame.\n",
    "    \"\"\"\n",
    "    h, w = img[0].shape\n",
    "    frame = np.zeros((h*n, w*n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            h_pos, w_pos = i*h, j*w\n",
    "            frame[h_pos:h_pos+h, w_pos:w_pos+w] = img[i*n+j]\n",
    "    return frame\n",
    "\n",
    "def diag_mask(h, w, right):\n",
    "    c = w / h\n",
    "    mask = np.full((h, w), True)\n",
    "    for y in range(h):\n",
    "        mask[y, :int(y*c)] = False\n",
    "    if right:\n",
    "        mask = mask[:, ::-1]\n",
    "    return mask\n",
    "\n",
    "def roi_mask(img, top_point, bot_height):\n",
    "    # Get image dimensions:\n",
    "    h, w = img.shape\n",
    "    # Get top point positions:\n",
    "    p_y, p_x = top_point\n",
    "    # Get mask:\n",
    "    mask = np.hstack((diag_mask(p_y-bot_height, p_x, True), \n",
    "                      diag_mask(p_y-bot_height, w-p_x, False)))\n",
    "    mask = np.vstack((np.full((h-p_y, w), True), mask))\n",
    "    mask = np.vstack((mask, np.full((bot_height, w), False)))\n",
    "    return mask\n",
    "\n",
    "def get_lines(img, seg):\n",
    "    # Read image & convert to grayscale:\n",
    "    img = cv2.resize(img, (512, 256), interpolation=cv2.INTER_LINEAR)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    # Gaussian filter to remove noises:\n",
    "    blur = cv2.GaussianBlur(gray,(3,3),0)\n",
    "    # Canny edge detection:\n",
    "    edges = cv2.Canny(blur,40,80,apertureSize = 3)\n",
    "    # Region of interest:\n",
    "    mask = roi_mask(edges, (150, 256), 50)\n",
    "    # Filter the region of interest:\n",
    "    edges[mask] = 0.0\n",
    "    # Hough line detection:\n",
    "    minLineLength = 100\n",
    "    maxLineGap = 10\n",
    "    lines = cv2.HoughLinesP(edges,1,np.pi/180,100,minLineLength,maxLineGap)\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            cv2.line(seg,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResUNet(\n",
       "  (encode1): DoubleConv(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (encode2): ResDown(\n",
       "    (down): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): ResDoubleConv(\n",
       "        (residual): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encode3): ResDown(\n",
       "    (down): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): ResDoubleConv(\n",
       "        (residual): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encode4): ResDown(\n",
       "    (down): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): ResDoubleConv(\n",
       "        (residual): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bottleneck): ResDown(\n",
       "    (down): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): ResDoubleConv(\n",
       "        (residual): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decode4): ResUp(\n",
       "    (up): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (double_conv): ResDoubleConv(\n",
       "      (residual): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decode3): ResUp(\n",
       "    (up): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (double_conv): ResDoubleConv(\n",
       "      (residual): Sequential(\n",
       "        (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decode2): ResUp(\n",
       "    (up): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (double_conv): ResDoubleConv(\n",
       "      (residual): Sequential(\n",
       "        (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decode1): Up(\n",
       "    (up): ConvTranspose2d(32, 16, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (double_conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out): Conv2d(16, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn = Drivable(new_size=(448, 224))\n",
    "# Get available device:\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Initialize a model:\n",
    "unet = ResUNet(in_channels=1, \n",
    "            out_channels=3, \n",
    "            init_features=16,\n",
    "            bias=False)\n",
    "#unet = nn.DataParallel(unet)\n",
    "# Load pretrained parameters:\n",
    "unet.load_state_dict(torch.load('saved_models\\\\16.07.20_unet_10_val_nll=-0.1609.pt', map_location='cpu'))\n",
    "# Load model to current device:\n",
    "unet.to(device)\n",
    "# Toggle evaluation mode:\n",
    "unet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-13d9dc0a4957>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# Our operations on the frame come here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;31m# Resize camera frame:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.2.0) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "n = 1\n",
    "cap = cv2.VideoCapture(2)\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Our operations on the frame come here\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # Resize camera frame:\n",
    "    frame = fn.resize(frame)\n",
    "    # Normalize image frame:\n",
    "    seg = fn.image_transform(frame)\n",
    "    # Convert np.array to torch tensor and push to device:\n",
    "    seg = torch.from_numpy(seg).to(device)\n",
    "    \"\"\"# Divide image frame into fragments to utilize GPUs:\n",
    "    seg = fragment(seg, n, True)\n",
    "    # Stack frame fragments into batch of tensors:\n",
    "    seg = torch.stack(seg)\"\"\"\n",
    "    seg = seg.unsqueeze(0)\n",
    "    # Segmentation model:\n",
    "    with torch.no_grad():\n",
    "        seg = unet(seg)\n",
    "    # Get the predict label (with highest probability):\n",
    "    seg = seg.argmax(dim=1).cpu().numpy()[0]\n",
    "    \"\"\"# Compress fragments to a single frame:\n",
    "    seg = glue_fragments(seg, n)\"\"\"\n",
    "    # Convert to colored frame:\n",
    "    seg = fn.convert_color(seg, False)\n",
    "    seg = seg[:,:,::-1]\n",
    "    seg = cv2.resize(seg, (720, 360), interpolation=cv2.INTER_AREA)\n",
    "    #frame = cv2.resize(frame, (720, 360), interpolation=cv2.INTER_LINEAR)\n",
    "    #seg = paint_path(seg, (89, 92))\n",
    "\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame',seg)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
